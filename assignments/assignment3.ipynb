{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1.\n",
    "\n",
    "**Correct answer:**\n",
    "ii. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates.\n",
    "\n",
    "**Reason:** There are no further information about how the interactions (i.e. $X4$ and $X5$) does look like. So I have to assume something:\n",
    "\n",
    "Looking at question 3 I assume $X4=\\frac{X1}{X2}$. Since $X3 \\in [0,1]$, I would not assume $X5=\\frac{X1}{X3}$, because this could end in an devision by zero. Therefore I assume it the other way around, i.e. $X5=\\frac{X3}{X1}$, (assuming that there is no data with a GPA < 2.0, because otherwise they would have been no graduates). Also the interaction $X5=X1*X3$ makes no sense, because this would result in a smaller salary when having a better GPA. (So I assume a higher salay for college graduates when having a higher GPA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Since GPA (X1) and IQ (X2) are fixed, X4 is also fixed. So the statement depends on X3 and X5, which means that we have to show that there is a minimal value for $X1 \\geq 2.0$ so that the part of the estimatied function containing the relevant predictors in our case, i.e. X3 and X5, is greater than 0, because both terms would be zero with my assumptions when having a high school graduate:\n",
    "$$\n",
    "\\hat{\\beta}_3*X3 + \\hat{\\beta}_5\\frac{X3}{X1} > 0 \\text{ | insert slopes and predictors}\n",
    "\\\\\n",
    "35*1-10\\frac{1}{X1} > 0 \\text{ | } +\\frac{10}{X1}\n",
    "\\\\\n",
    "35 > \\frac{10}{X1} \\text{ | } * X1\n",
    "\\\\\n",
    "35X1 > 10 \\text{ | } / 35\n",
    "\\\\\n",
    "X1 > \\frac{10}{35}\n",
    "$$\n",
    "So the minimal value for the GPA would be $\\frac{10}{35}=0.29$. But considering the domain here, it is impossible to graduate with a GPA < 2.0. So a college graduate is estimated to earn more than a high school graduate either way. (based on my assumptions above)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### A.2.\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1X1 + \\hat{\\beta}_2X2 + \\hat{\\beta}_3X3 + \\hat{\\beta}_4X4 + \\hat{\\beta}_5X5 \\text{ | insert estimated interception and slope}\n",
    "\\\\\n",
    "\\hat{y} = 50 + 20X1 + 0.07X2 + 35X3 + 0.01X4 + (-10)X5 \\text{ | insert predictor values, with } X4=\\frac{X1}{X2} \\text{ and } X5=\\frac{X3}{X1}\n",
    "\\\\\n",
    "\\hat{y} = 50 + 20*4.0 + 0.07*110 + 35*1 + 0.01*\\frac{4.0}{110}  -10 *\\frac{1}{4.0} \\text{ | calculate}\n",
    "\\\\\n",
    "\\hat{y} = 170.204\n",
    "$$\n",
    "So the predicted salary for the given predictors is 170204\\$ (based on my assumptions from A.1.).\n",
    "\n",
    "\n",
    "\n",
    "### A.3.\n",
    "**False:** The (regression) coefficient was estimated for the estimation of a function that estimates the salary based on specific data. It does not tell anything about the interaction/correlation between the predictors used in this estimation, even if it is very small. If we want to find evidence for the interaction between two predictors, we need to consider the correletion coefficient of the two predictors (i.e. GPA and IQ). Even a look at the t-statistic and the p-value would give only information about the dependency between the interaction of the predictors itself and the estimated outcome of the estimates function, but not about the interaction between theses predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical part (Assigment 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('/media/home/ngundermann/workspace/MachineLearning/data/ISLR/data/Boston.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Check again the accuracy of the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.708\n",
      "Model:                            OLS   Adj. R-squared:                  0.705\n",
      "Method:                 Least Squares   F-statistic:                     242.6\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          3.67e-131\n",
      "Time:                        09:12:23   Log-Likelihood:                -1528.7\n",
      "No. Observations:                 506   AIC:                             3069.\n",
      "Df Residuals:                     500   BIC:                             3095.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept     37.4992      4.613      8.129      0.000      28.436      46.562\n",
      "lstat         -0.5811      0.048    -12.122      0.000      -0.675      -0.487\n",
      "rm             4.1633      0.412     10.104      0.000       3.354       4.973\n",
      "nox          -17.9966      3.261     -5.519      0.000     -24.403     -11.590\n",
      "dis           -1.1847      0.168     -7.034      0.000      -1.516      -0.854\n",
      "ptratio       -1.0458      0.114     -9.212      0.000      -1.269      -0.823\n",
      "==============================================================================\n",
      "Omnibus:                      187.456   Durbin-Watson:                   0.971\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              885.498\n",
      "Skew:                           1.584   Prob(JB):                    5.21e-193\n",
      "Kurtosis:                       8.654   Cond. No.                         545.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from ISLP.models import ModelSpec as MS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = MS(['lstat', 'rm', 'nox', 'dis', 'ptratio']).fit_transform(df)\n",
    "y = df['medv']\n",
    "lm1 = sm.OLS(y,X).fit()\n",
    "print(lm1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Add interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.778\n",
      "Model:                            OLS   Adj. R-squared:                  0.775\n",
      "Method:                 Least Squares   F-statistic:                     290.8\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          2.48e-159\n",
      "Time:                        09:12:23   Log-Likelihood:                -1459.9\n",
      "No. Observations:                 506   AIC:                             2934.\n",
      "Df Residuals:                     499   BIC:                             2963.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      3.1518      4.880      0.646      0.519      -6.435      12.739\n",
      "lstat          1.8115      0.196      9.237      0.000       1.426       2.197\n",
      "rm             8.3344      0.491     16.971      0.000       7.370       9.299\n",
      "nox          -12.3651      2.885     -4.286      0.000     -18.033      -6.697\n",
      "dis           -1.0184      0.148     -6.893      0.000      -1.309      -0.728\n",
      "ptratio       -0.7152      0.103     -6.967      0.000      -0.917      -0.514\n",
      "lstat*rm      -0.4185      0.034    -12.488      0.000      -0.484      -0.353\n",
      "==============================================================================\n",
      "Omnibus:                      246.928   Durbin-Watson:                   1.079\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2792.613\n",
      "Skew:                           1.836   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.908   Cond. No.                     2.36e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.36e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "df['lstat*rm'] = df['lstat']*df['rm']\n",
    "\n",
    "X = MS(['lstat', 'rm', 'nox', 'dis', 'ptratio', 'lstat*rm']).fit_transform(df)\n",
    "y = df['medv']\n",
    "lm2 = sm.OLS(y,X).fit()\n",
    "print(lm2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Interprete the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interaction term of lstat and rm (lstat*rm) leads to an overall improvement of the fitted function, which can be shown by the higher R² value. According to the p-value the coefficient of the interaction term seems to be significant (p < 5%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Apply non-linear transformations to some predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.781\n",
      "Model:                            OLS   Adj. R-squared:                  0.778\n",
      "Method:                 Least Squares   F-statistic:                     253.9\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          8.05e-160\n",
      "Time:                        09:12:23   Log-Likelihood:                -1455.8\n",
      "No. Observations:                 506   AIC:                             2928.\n",
      "Df Residuals:                     498   BIC:                             2961.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "intercept      10.5522      5.499      1.919      0.056      -0.253      21.357\n",
      "lstat           1.5468      0.216      7.167      0.000       1.123       1.971\n",
      "rm              7.6004      0.552     13.777      0.000       6.516       8.684\n",
      "nox           -12.2898      2.865     -4.290      0.000     -17.918      -6.662\n",
      "dis            -1.0641      0.148     -7.209      0.000      -1.354      -0.774\n",
      "ptratio        -0.7112      0.102     -6.977      0.000      -0.912      -0.511\n",
      "(lstat*rm)2     0.0004      0.000      2.845      0.005       0.000       0.001\n",
      "lstat*rm       -0.4468      0.035    -12.864      0.000      -0.515      -0.379\n",
      "==============================================================================\n",
      "Omnibus:                      217.415   Durbin-Watson:                   1.059\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2007.945\n",
      "Skew:                           1.622   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.204   Cond. No.                     3.02e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.02e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "df['(lstat*rm)2'] = df['lstat*rm']*df['lstat*rm']\n",
    "\n",
    "X = MS(['lstat', 'rm', 'nox', 'dis', 'ptratio', '(lstat*rm)2', 'lstat*rm']).fit_transform(df)\n",
    "y = df['medv']\n",
    "lm3 = sm.OLS(y,X).fit()\n",
    "print(lm3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Use ANOVA to check if the quadratic fit is superior to the linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_resid</th>\n",
       "      <th>ssr</th>\n",
       "      <th>df_diff</th>\n",
       "      <th>ss_diff</th>\n",
       "      <th>F</th>\n",
       "      <th>Pr(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499.0</td>\n",
       "      <td>9500.381881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498.0</td>\n",
       "      <td>9348.435955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>151.945925</td>\n",
       "      <td>8.094303</td>\n",
       "      <td>0.004623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df_resid          ssr  df_diff     ss_diff         F    Pr(>F)\n",
       "0     499.0  9500.381881      0.0         NaN       NaN       NaN\n",
       "1     498.0  9348.435955      1.0  151.945925  8.094303  0.004623"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "anova_lm(lm2, lm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Interprete the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the linear fit, this model reached a R²-value of 0.781, which is the best so far. It also seems that all used predictors are useful, since the p-values of the t-statistics are all lower than 5%.\n",
    "\n",
    "The output of the anova test shows the two models in realtion to the previous model. Since there is no previous model of the first model, the comparing columns (ssr, df_diff, ss_diff, F and Pr(>F)) are NaN or zero. In order to compare the two models. we have to look at these columns in the second line. Here the second model with the non linear predictor shows a better RSS since it is approx. 152 points lower than in the first model. Also the F statistic is a little bit higher and this increase is significant, since the p-value is lower than 5% (last column). So the non linear model seems to be the better fit here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Check if including additional polynomial terms, up to order, lead to an improvement in the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.792\n",
      "Model:                            OLS   Adj. R-squared:                  0.787\n",
      "Method:                 Least Squares   F-statistic:                     188.0\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          1.80e-161\n",
      "Time:                        09:12:23   Log-Likelihood:                -1443.5\n",
      "No. Observations:                 506   AIC:                             2909.\n",
      "Df Residuals:                     495   BIC:                             2956.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept     33.9246      7.663      4.427      0.000      18.869      48.981\n",
      "lstat         -5.6422      1.426     -3.957      0.000      -8.444      -2.841\n",
      "rm             6.5291      0.711      9.183      0.000       5.132       7.926\n",
      "nox          -13.7513      2.823     -4.871      0.000     -19.298      -8.204\n",
      "dis           -1.0326      0.145     -7.127      0.000      -1.317      -0.748\n",
      "ptratio       -0.7407      0.101     -7.324      0.000      -0.939      -0.542\n",
      "(lstat)2       0.8633      0.187      4.622      0.000       0.496       1.230\n",
      "(lstat)3      -0.0495      0.012     -4.153      0.000      -0.073      -0.026\n",
      "(lstat)4       0.0013      0.000      3.795      0.000       0.001       0.002\n",
      "(lstat)5   -1.279e-05   3.64e-06     -3.514      0.000   -1.99e-05   -5.64e-06\n",
      "lstat*rm      -0.3055      0.052     -5.878      0.000      -0.408      -0.203\n",
      "==============================================================================\n",
      "Omnibus:                      232.049   Durbin-Watson:                   1.116\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2275.267\n",
      "Skew:                           1.742   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.787   Cond. No.                     3.38e+08\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.38e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for i in range(2,n+1):\n",
    "    df[f'(lstat){i}'] = df['lstat'] ** i\n",
    "\n",
    "X = MS(['lstat', 'rm', 'nox', 'dis', 'ptratio', '(lstat)2', '(lstat)3', '(lstat)4', '(lstat)5', 'lstat*rm']).fit_transform(df)\n",
    "y = df['medv']\n",
    "lm4 = sm.OLS(y,X).fit()\n",
    "print(lm4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Use ANOVA to check if the quadratic fit is superior to the linear fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_resid</th>\n",
       "      <th>ssr</th>\n",
       "      <th>df_diff</th>\n",
       "      <th>ss_diff</th>\n",
       "      <th>F</th>\n",
       "      <th>Pr(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499.0</td>\n",
       "      <td>9500.381881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495.0</td>\n",
       "      <td>8903.772453</td>\n",
       "      <td>4.0</td>\n",
       "      <td>596.609428</td>\n",
       "      <td>8.292038</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df_resid          ssr  df_diff     ss_diff         F    Pr(>F)\n",
       "0     499.0  9500.381881      0.0         NaN       NaN       NaN\n",
       "1     495.0  8903.772453      4.0  596.609428  8.292038  0.000002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova_lm(lm2, lm4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Interprete the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the linear fit, this model reached a R²-value of 0.792, which is the best so far. It also seems that all used predictors are useful, since the p-values of the t-statistics are all lower than 5%.\n",
    "\n",
    "The output of the avona test shows the two models in realtion to the previous model. Since there is no previous model of the first model, the comparing columns (ssr, df_diff, ss_diff, F and Pr(>F)) are NaN or zero. In order to compare the two models, we have to look at these columns in the second line. Here the second model with the polynomial predictor shows a better RSS since it is approx. 597 points lower than in the linar model. Also the F statistic is a little bit higher and this increase is significant, since the p-value is lower than 5% (last column). So the polynomial model seems to be the better fit here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Fit and assess other non-linear transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.804\n",
      "Model:                            OLS   Adj. R-squared:                  0.800\n",
      "Method:                 Least Squares   F-statistic:                     202.6\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          7.10e-168\n",
      "Time:                        09:12:23   Log-Likelihood:                -1428.4\n",
      "No. Observations:                 506   AIC:                             2879.\n",
      "Df Residuals:                     495   BIC:                             2925.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept    172.9866     13.954     12.397      0.000     145.571     200.402\n",
      "lstat         -8.5527      1.227     -6.969      0.000     -10.964      -6.141\n",
      "rm            25.1967      2.732      9.224      0.000      19.830      30.564\n",
      "nox          -16.6408      2.734     -6.087      0.000     -22.012     -11.270\n",
      "dis           -0.9709      0.141     -6.885      0.000      -1.248      -0.694\n",
      "ptratio       -0.7843      0.097     -8.116      0.000      -0.974      -0.594\n",
      "(lstat)2       1.0064      0.178      5.654      0.000       0.657       1.356\n",
      "(lstat)3      -0.0582      0.011     -5.087      0.000      -0.081      -0.036\n",
      "(lstat)4       0.0015      0.000      4.672      0.000       0.001       0.002\n",
      "(lstat)5   -1.521e-05   3.52e-06     -4.323      0.000   -2.21e-05    -8.3e-06\n",
      "log(rm)     -137.4038     16.761     -8.198      0.000    -170.336    -104.472\n",
      "==============================================================================\n",
      "Omnibus:                      221.958   Durbin-Watson:                   1.064\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2718.500\n",
      "Skew:                           1.567   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.914   Cond. No.                     9.63e+08\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.63e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['log(rm)'] = np.log(df['rm'])\n",
    "\n",
    "X = MS(['lstat', 'rm', 'nox', 'dis', 'ptratio', '(lstat)2', '(lstat)3', '(lstat)4', '(lstat)5', 'log(rm)']).fit_transform(df)\n",
    "y = df['medv']\n",
    "lm5 = sm.OLS(y,X).fit()\n",
    "print(lm5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_resid</th>\n",
       "      <th>ssr</th>\n",
       "      <th>df_diff</th>\n",
       "      <th>ss_diff</th>\n",
       "      <th>F</th>\n",
       "      <th>Pr(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499.0</td>\n",
       "      <td>9500.381881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495.0</td>\n",
       "      <td>8386.756361</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1113.62552</td>\n",
       "      <td>16.431997</td>\n",
       "      <td>1.190966e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df_resid          ssr  df_diff     ss_diff          F        Pr(>F)\n",
       "0     499.0  9500.381881      0.0         NaN        NaN           NaN\n",
       "1     495.0  8386.756361      4.0  1113.62552  16.431997  1.190966e-12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova_lm(lm2, lm5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Interprete the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the linear fit, this model reached a R²-value of 0.804, which is the best so far. It also seems that all used predictors are useful, since the p-values of the t-statistics are all lower than 5%.\n",
    "\n",
    "\n",
    "The output of the anova test shows the two models in realtion to the previous model. Since there is no previous model of the first model, the comparing columns (ssr, df_diff, ss_diff, F and Pr(>F)) are NaN or zero. In order to compare the two models, we have to look at these columns in the second line. Here the second model with the log predictor shows a better RSS since it is approx. 1114 points lower than in the linar model. Also the F statistic is a little bit higher and this increase is significant, since the p-value is lower than 5% (last column). So the model with the log predictor seems to be the better fit here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Use categorical predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    400.000000\n",
      "mean       7.496325\n",
      "std        2.824115\n",
      "min        0.000000\n",
      "25%        5.390000\n",
      "50%        7.490000\n",
      "75%        9.320000\n",
      "max       16.270000\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "count    400.000000\n",
      "mean     124.975000\n",
      "std       15.334512\n",
      "min       77.000000\n",
      "25%      115.000000\n",
      "50%      125.000000\n",
      "75%      135.000000\n",
      "max      175.000000\n",
      "Name: CompPrice, dtype: float64\n",
      "\n",
      "count    400.000000\n",
      "mean      68.657500\n",
      "std       27.986037\n",
      "min       21.000000\n",
      "25%       42.750000\n",
      "50%       69.000000\n",
      "75%       91.000000\n",
      "max      120.000000\n",
      "Name: Income, dtype: float64\n",
      "\n",
      "count    400.000000\n",
      "mean       6.635000\n",
      "std        6.650364\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        5.000000\n",
      "75%       12.000000\n",
      "max       29.000000\n",
      "Name: Advertising, dtype: float64\n",
      "\n",
      "count    400.000000\n",
      "mean     264.840000\n",
      "std      147.376436\n",
      "min       10.000000\n",
      "25%      139.000000\n",
      "50%      272.000000\n",
      "75%      398.500000\n",
      "max      509.000000\n",
      "Name: Population, dtype: float64\n",
      "\n",
      "count    400.000000\n",
      "mean     115.795000\n",
      "std       23.676664\n",
      "min       24.000000\n",
      "25%      100.000000\n",
      "50%      117.000000\n",
      "75%      131.000000\n",
      "max      191.000000\n",
      "Name: Price, dtype: float64\n",
      "\n",
      "count        400\n",
      "unique         3\n",
      "top       Medium\n",
      "freq         219\n",
      "Name: ShelveLoc, dtype: object\n",
      "\n",
      "count    400.000000\n",
      "mean      53.322500\n",
      "std       16.200297\n",
      "min       25.000000\n",
      "25%       39.750000\n",
      "50%       54.500000\n",
      "75%       66.000000\n",
      "max       80.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "count    400.000000\n",
      "mean      13.900000\n",
      "std        2.620528\n",
      "min       10.000000\n",
      "25%       12.000000\n",
      "50%       14.000000\n",
      "75%       16.000000\n",
      "max       18.000000\n",
      "Name: Education, dtype: float64\n",
      "\n",
      "count     400\n",
      "unique      2\n",
      "top       Yes\n",
      "freq      282\n",
      "Name: Urban, dtype: object\n",
      "\n",
      "count     400\n",
      "unique      2\n",
      "top       Yes\n",
      "freq      258\n",
      "Name: US, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv('/media/home/ngundermann/workspace/MachineLearning/data/ISLR/data/Carseats.csv', index_col=0)\n",
    "for column in df.columns.values:\n",
    "    print(f'{df[column].describe()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: For the categorical predictors, generate dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Urban_dummy'] = np.where(df['Urban'] == 'Yes', 1, 0)\n",
    "df['US_dummy'] = np.where(df['US'] == 'Yes', 1, 0)\n",
    "df['ShelveLoc_Good_dummy'] = np.where(df['ShelveLoc'] == 'Good', 1, 0)\n",
    "df['ShelveLoc_Medium_dummy'] = np.where(df['ShelveLoc'] == 'Medium', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.873\n",
      "Model:                            OLS   Adj. R-squared:                  0.870\n",
      "Method:                 Least Squares   F-statistic:                     243.4\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          1.60e-166\n",
      "Time:                        09:12:24   Log-Likelihood:                -568.99\n",
      "No. Observations:                 400   AIC:                             1162.\n",
      "Df Residuals:                     388   BIC:                             1210.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "intercept                  5.6606      0.603      9.380      0.000       4.474       6.847\n",
      "CompPrice                  0.0928      0.004     22.378      0.000       0.085       0.101\n",
      "Income                     0.0158      0.002      8.565      0.000       0.012       0.019\n",
      "Advertising                0.1231      0.011     11.066      0.000       0.101       0.145\n",
      "Population                 0.0002      0.000      0.561      0.575      -0.001       0.001\n",
      "Price                     -0.0954      0.003    -35.700      0.000      -0.101      -0.090\n",
      "Age                       -0.0460      0.003    -14.472      0.000      -0.052      -0.040\n",
      "Education                 -0.0211      0.020     -1.070      0.285      -0.060       0.018\n",
      "Urban_dummy                0.1229      0.113      1.088      0.277      -0.099       0.345\n",
      "US_dummy                  -0.1841      0.150     -1.229      0.220      -0.479       0.111\n",
      "ShelveLoc_Good_dummy       4.8502      0.153     31.678      0.000       4.549       5.151\n",
      "ShelveLoc_Medium_dummy     1.9567      0.126     15.516      0.000       1.709       2.205\n",
      "==============================================================================\n",
      "Omnibus:                        0.811   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.667   Jarque-Bera (JB):                0.765\n",
      "Skew:                           0.107   Prob(JB):                        0.682\n",
      "Kurtosis:                       2.994   Cond. No.                     4.15e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.15e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "rel_columns = list(filter((lambda name: name != 'Sales' and name != 'US' and name != 'Urban' and name != 'ShelveLoc'), df.columns.values))\n",
    "X = MS(rel_columns).fit_transform(df)\n",
    "y = df['Sales']\n",
    "lm6 = sm.OLS(y,X).fit()\n",
    "print(lm6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Interprete the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model is an overall good model, since the R² value is quite high at 0.873. Anyway there are some predictors that might be irrelevant, since the p-value if higher than 5%, i.e. US_dummy, Urban_dummy, Education and population. So it seems that the US predictor, the Urban predictor, the Population and the education does not play a role according to the prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I: Play around with the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.877\n",
      "Model:                            OLS   Adj. R-squared:                  0.875\n",
      "Method:                 Least Squares   F-statistic:                     310.0\n",
      "Date:                Fri, 02 Feb 2024   Prob (F-statistic):          1.15e-171\n",
      "Time:                        09:12:24   Log-Likelihood:                -562.67\n",
      "No. Observations:                 400   AIC:                             1145.\n",
      "Df Residuals:                     390   BIC:                             1185.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "intercept                  2.5208      1.186      2.126      0.034       0.189       4.852\n",
      "CompPrice                  0.1187      0.010     12.441      0.000       0.100       0.137\n",
      "Income                     0.0566      0.016      3.628      0.000       0.026       0.087\n",
      "Advertising                0.0637      0.020      3.112      0.002       0.023       0.104\n",
      "Price                     -0.0952      0.003    -36.324      0.000      -0.100      -0.090\n",
      "Age                       -0.0454      0.003    -14.519      0.000      -0.052      -0.039\n",
      "ShelveLoc_Good_dummy       4.8417      0.150     32.338      0.000       4.547       5.136\n",
      "ShelveLoc_Medium_dummy     1.9304      0.123     15.645      0.000       1.688       2.173\n",
      "Income*CompPrice          -0.0004      0.000     -2.984      0.003      -0.001      -0.000\n",
      "Income*Advertising         0.0007      0.000      2.694      0.007       0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                        1.037   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.595   Jarque-Bera (JB):                0.895\n",
      "Skew:                           0.112   Prob(JB):                        0.639\n",
      "Kurtosis:                       3.061   Cond. No.                     2.20e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.2e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "irrelevant_columns = ['Sales', 'US', 'Urban', 'ShelveLoc', \n",
    "                      'Education', 'Population', 'US_dummy', 'Urban_dummy' ]\n",
    "\n",
    "df['Income*CompPrice'] = df['Income'] * df['CompPrice']\n",
    "df['Income*Advertising'] = df['Income'] * df['Advertising']\n",
    "\n",
    "rel_columns = list(filter((lambda name: name not in irrelevant_columns), df.columns.values))\n",
    "\n",
    "X = MS(rel_columns).fit_transform(df)\n",
    "y = df['Sales']\n",
    "lm7 = sm.OLS(y,X).fit()\n",
    "print(lm7.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaten! (by 0.007 R²)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
